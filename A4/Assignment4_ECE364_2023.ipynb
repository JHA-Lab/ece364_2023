{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E32UBMT7VKMm"
   },
   "source": [
    "## Prepare python environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y_lm7Q-9VKMn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryOZJYQa3PG0"
   },
   "outputs": [],
   "source": [
    "random_state = 5 # use this to control randomness across runs e.g., dataset partitioning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BASGXrOy4wat"
   },
   "source": [
    "## Preparing the Diabetes Dataset (2 points)\n",
    "\n",
    "We will use the diabetes dataset from the UCI machine learning repository. Details about this dataset can be found [here](https://www.kaggle.com/uciml/pima-indians-diabetes-database). The objective of this project is to predict whether or not a female patient has diabetes based on diagnostic measurements in the dataset.\n",
    "\n",
    "The dataset consists of several medical predictor variables (features) and one target variable indicating whether or not the person has diabetes. Predictor variables include the number of pregnancies the patient has had, glucose level, blood pressure, skin, insulin, bmi, pedigree, and age."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URgO9HCN6RCl"
   },
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "id": "tlKBDyEQDzrk",
    "outputId": "e7cd7a50-c7df-4b70-eb5a-42797566e3ca"
   },
   "outputs": [],
   "source": [
    "# These are the names of the columns in the dataset. They includes all features of the data and the label.\n",
    "col_names = ['pregnancies', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']\n",
    "\n",
    "# Download and load the dataset\n",
    "import os\n",
    "if not os.path.exists('diabetes.csv'): \n",
    "    !wget https://raw.githubusercontent.com/JHA-Lab/ece364_2023/master/dataset/diabetes.csv \n",
    "diabetes_data = pd.read_csv('diabetes.csv', header=1, names=col_names)\n",
    "\n",
    "FEATURE_NAMES=diabetes_data.drop('label',axis=1).columns\n",
    "\n",
    "# Display the first five instances in the dataset\n",
    "diabetes_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U1ds9iRBPJwr"
   },
   "outputs": [],
   "source": [
    "# Check the type of data in each column\n",
    "diabetes_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use the `describe` function to display some statistics of the data. See [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.describe.html) for details about this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some stats\n",
    "diabetes_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Count tells us the number of non-empty rows in a feature.\n",
    "\n",
    "2. Mean tells us the mean value of that feature.\n",
    "\n",
    "3. Std tells us the standard deviation of that feature.\n",
    "\n",
    "4. Min tells us the minimum value of that feature.\n",
    "\n",
    "5. 25%, 50%, and 75% are the percentile/quartiles of each feature.\n",
    "\n",
    "6. Max tells us the maximum value of that feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize the distribution of fraudulent vs genuine transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.pie(diabetes_data.label.value_counts(),autopct='%1.1f%%', labels=['Not diabetes','Diabetes'], colors=['green','red'])\n",
    "plt.axis('equal')\n",
    "plt.ylabel('');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRhEcln77rIK"
   },
   "source": [
    "### Extract target and descriptive features (0.5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "blhp_Upk8E-Y"
   },
   "outputs": [],
   "source": [
    "# Store all the features from the data in X\n",
    "X = # TODO\n",
    "# Store all the labels in y\n",
    "y = # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gdUFK3qG8Gnk",
    "outputId": "8ba6b912-914b-40eb-8317-b3829e2d7e2a"
   },
   "outputs": [],
   "source": [
    "# Convert data to numpy array\n",
    "X = # TODO\n",
    "y = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N-JPYSnc8JQi"
   },
   "source": [
    "### Create training and validation datasets (0.5 points)\n",
    "\n",
    "\n",
    "Split the data into training and validation sets using `train_test_split`.  See [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) for details. To get consistent result while splitting, set `random_state` to the value defined earlier. We use 80% of the data for training and 20% of the data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzTzI3iT8R5x"
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hc40XakM8ZjC"
   },
   "source": [
    "### Preprocess the dataset (1 point)\n",
    "\n",
    "#### Preprocess the data by normalizing each feature to have zero mean and unit standard deviation. This can be done using the `StandardScaler()` function. See [here](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) for more details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBcVWz4M8qi3"
   },
   "outputs": [],
   "source": [
    "# Define the scaler for scaling the data\n",
    "scaler = # TODO\n",
    "\n",
    "# Normalize the training data\n",
    "X_train = # TODO\n",
    "\n",
    "# Use the scaler defined above to standardize the validation data by applying the same transformation to the validation data.\n",
    "X_val = # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V0ytKO6K6rW-"
   },
   "source": [
    "## Training error-based models (18 points)\n",
    "\n",
    "\n",
    "#### We will use the `sklearn` library to train a Multinomial Logistic Regression classifier and Support Vector Machines. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBAcnfZw6rW_"
   },
   "source": [
    "### Exercise 1:  Learning a Multinomial Logistic Regression classifier (4 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sZY5Qfz36rW_"
   },
   "source": [
    "#### Use `sklearn`'s `SGDClassifier` to train a multinomial logistic regression classifier (i.e., using a one-versus-rest scheme) with Stochastic Gradient Descent. Review ch.7 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier) for more details. \n",
    "\n",
    "#### Set the `random_state` as defined above,  increase the `n_iter_no_change` to 1000 and `max_iter` to 10000 to facilitate better convergence.  \n",
    "\n",
    "#### Report the model's accuracy over the training and validation sets.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJ3SYc4J6rW_"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y1hqKVGd6rW_",
    "outputId": "4404614b-6c8c-4c3a-ee95-a6daf432db74"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cV7PfP9G6rXA"
   },
   "source": [
    "#### Explain any performance difference observed between the training and validation datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r080wHsO6rXA"
   },
   "source": [
    "Insert answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IctolF7v6rXA"
   },
   "source": [
    "### Exercise 2: Learning a Support Vector Machine (SVM) (14 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7uWiMMUs6rXA"
   },
   "source": [
    "#### Use `sklearn`'s `SVC` class to train an SVM (i.e., using a [one-versus-one scheme](https://en.wikipedia.org/wiki/Multiclass_classification#One-vs.-one)). Review ch.7 and see [here](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html) for more details. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jyp0Jj3x6rXA"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U5dxvcSK6rXA"
   },
   "source": [
    "#### Exercise 2a: Warm up (2 points)\n",
    "\n",
    "#### Train an SVM with a linear kernel. Set the  random_state to the value defined above. Keep all other parameters at their defaults.\n",
    "\n",
    "#### Report the model's accuracy over the training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REdlLnyO6rXB",
    "outputId": "d71ae012-c6f3-4d85-d743-62484f6c7b7c"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJELdAX36rXB"
   },
   "source": [
    "#### Exercise 2b: Evaluate a polynomial kernel function (4 points)\n",
    "\n",
    "#### Try fitting an SVM with a polynomial kernel function and vary the degree among {1, 2, 3, 4}. Note that degree=1 yields a linear kernel. \n",
    "\n",
    "#### For each fitted classifier, report its accuracy over the training and validation sets. \n",
    "\n",
    "#### As before, set the random_state to the value defined above. Set the regularization strength `C=100`.  When the data is not linearly separable, this encourages the model to fit the training data. Keep all other parameters at their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B6T71FR_6rXB",
    "outputId": "eaeaf670-1631-4915-9822-590dca6cdffe"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdzaOyzg6rXB"
   },
   "source": [
    "#### Explain the effect of increasing the degree of the polynomial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vBeZEsy_6rXB"
   },
   "source": [
    "Insert answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GYfgKZuZ6rXB"
   },
   "source": [
    "#### Exercise 2c: Evaluate the radial basis kernel function (6 points)\n",
    "\n",
    "#### Try fitting an SVM with a radial basis kernel function and vary the length-scale parameter given by $\\gamma$ among {0.01, 0.1,1,10, 100}. \n",
    "\n",
    "#### For each fitted classifier, report its accuracy over the training and validation sets. \n",
    "\n",
    "#### As before, set the random_state to the value defined above. Set the regularization strength `C=100`.  When the data is not linearly separable, this encourages the model to fit the training data (read more [here](https://scikit-learn.org/stable/auto_examples/svm/plot_rbf_parameters.html)). Keep all other parameters at their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3BCoYu66rXC",
    "outputId": "d63244c7-88ad-4acb-a3ff-b94075f78392"
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dpzq9Ync6rXC"
   },
   "source": [
    "#### Comment on the effect of increasing/reducing the length-scale parameter $\\gamma$. Also, compare the performance of the classifiers trained with RBF kernel function against those trained with the polynomial and linear kernel functions (i.e., Ex. 2b). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M6_JKd8S6rXC"
   },
   "source": [
    "Insert answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhxJEJpS6rXC"
   },
   "source": [
    "#### Exercise 2d: Briefly state the main difference between the logistic regression classifier and the SVM. (2 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jPMmTUQ6rXD"
   },
   "source": [
    "Insert answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "nav_menu": {
   "height": "309px",
   "width": "468px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
